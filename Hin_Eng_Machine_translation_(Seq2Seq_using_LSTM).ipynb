{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hin-Eng Machine-translation (Seq2Seq using LSTM).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C98Mokc8K3Uu",
        "colab_type": "code",
        "outputId": "5507ce70-91d6-4068-e89a-80dfed6ce8a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "pip install indic-nlp-library"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: indic-nlp-library in /usr/local/lib/python3.6/dist-packages (0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from indic-nlp-library) (1.18.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from indic-nlp-library) (1.0.3)\n",
            "Requirement already satisfied: morfessor in /usr/local/lib/python3.6/dist-packages (from indic-nlp-library) (2.0.6)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->indic-nlp-library) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->indic-nlp-library) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->indic-nlp-library) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KE45-AvK_cL",
        "colab_type": "code",
        "outputId": "a550c476-e246-41b6-dd01-d4246be4112a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import codecs\n",
        "import torch\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import numpy as np\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gc4NMkjRHSll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 21\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rBXAaNnbpQ8",
        "colab_type": "code",
        "outputId": "51da68f8-6349-49b4-8800-8e3034337e18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgDrgOFaLn9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with codecs.open('/content/drive/My Drive/Colab Notebooks/traing_english.txt', encoding='utf-8') as f:\n",
        "  training_english = f.read().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JYBg6MLLxSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with codecs.open('/content/drive/My Drive/Colab Notebooks/traing_hindi.txt', encoding='utf-8') as f:\n",
        "  training_hindi = f.read().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rDGTNsbC_xy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "with codecs.open('/content/drive/My Drive/Colab Notebooks/testing_english.txt', encoding='utf-8') as f:\n",
        "  testing_english = f.read().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZeyc5XYDML_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with codecs.open('/content/drive/My Drive/Colab Notebooks/testing_hindi.txt', encoding='utf-8') as f:\n",
        "  testing_hindi = f.read().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnpCpm93Opmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from indicnlp.tokenize import indic_tokenize  \n",
        "from nltk.tokenize import RegexpTokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ngDYXIU8Pnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenizer(hindi, english, flag):\n",
        "  data = []\n",
        "  corpus_hindi = []\n",
        "  corpus_english = []\n",
        "  tokenizer_english = RegexpTokenizer('\\w+|\\$[\\.]+|\\S+')\n",
        "  for sentence_hindi, sentence_english in zip(hindi, english):\n",
        "    dic = {}\n",
        "    h = indic_tokenize.trivial_tokenize(sentence_hindi)\n",
        "    e = tokenizer_english.tokenize(sentence_english)\n",
        "\n",
        "    if flag:\n",
        "      corpus_hindi += h\n",
        "      corpus_english += e\n",
        "\n",
        "    dic['trg'] = e\n",
        "    dic['src'] = h\n",
        "    data.append(dic)\n",
        "  return data, corpus_hindi, corpus_english"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEW6QHEoPegr",
        "colab_type": "code",
        "outputId": "f959c710-1b2f-4987-b37f-9edd1777bdce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "training_data, corpus_hindi, corpus_english = tokenizer(training_hindi,training_english, True)\n",
        "training_data[0]"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'src': ['द्वारका', 'चार', 'धामों', 'में', 'एक', 'धाम', 'भी', 'है'],\n",
              " 'trg': ['dwarka',\n",
              "  'is',\n",
              "  'also',\n",
              "  'a',\n",
              "  'dhaam',\n",
              "  'among',\n",
              "  'the',\n",
              "  'chaar',\n",
              "  'dhaams']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rkox5OZ06M5W",
        "colab_type": "code",
        "outputId": "97f5d075-8d8d-4c57-cdf0-fdb929f1e76c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        }
      },
      "source": [
        "training_data[50]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'src': ['मेले',\n",
              "  'के',\n",
              "  'दौरान',\n",
              "  'तट',\n",
              "  'पर',\n",
              "  'तंबुओं',\n",
              "  'का',\n",
              "  'एक',\n",
              "  'पूरा',\n",
              "  'नगर',\n",
              "  'बस',\n",
              "  'जाता',\n",
              "  'है'],\n",
              " 'trg': ['one',\n",
              "  'whole',\n",
              "  'city',\n",
              "  'of',\n",
              "  'tents',\n",
              "  'gets',\n",
              "  'settled',\n",
              "  'on',\n",
              "  'the',\n",
              "  'banks',\n",
              "  'during',\n",
              "  'the',\n",
              "  'fair']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zez7alYOL8j",
        "colab_type": "code",
        "outputId": "4b641471-f944-4eea-9f82-b83e0b9c54a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "valid_test_data, _, _ = tokenizer(testing_hindi, testing_english, False)\n",
        "valid_test_data[0]"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'src': ['बैदाडीह', 'स्थान', 'बड़े', 'कुएँ', 'के', 'लिए', 'प्रसिद्ध', 'है'],\n",
              " 'trg': ['the',\n",
              "  'place',\n",
              "  'baidadih',\n",
              "  'is',\n",
              "  'famous',\n",
              "  'for',\n",
              "  'the',\n",
              "  'big',\n",
              "  'well']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PerTGpxyTFX-",
        "colab_type": "code",
        "outputId": "12b36d5e-72b8-48ef-d8ed-d790ed1e4d53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "valid_data = valid_test_data[:len(valid_test_data)//2]\n",
        "testing_data = valid_test_data[len(valid_test_data)//2:]\n",
        "print(len(valid_data))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9980\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3azoNg3vPMSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "counter_english = Counter(corpus_english)\n",
        "counter_hindi = Counter(corpus_hindi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwXx32biUqrb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_hindi = {'<sos>': 0,'<eos>': 1, '<unk>': 2, '<pad>': 3}\n",
        "count = 4\n",
        "for i,word in enumerate(corpus_hindi):\n",
        "  if word not in vocab_hindi and counter_hindi[word] > 1:\n",
        "    vocab_hindi[word] = count\n",
        "    count += 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0YrYBI0VF0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_english = {'<sos>': 0,'<eos>': 1, '<unk>': 2, '<pad>': 3}\n",
        "count = 4\n",
        "for i,word in enumerate(corpus_english):\n",
        "  if word not in vocab_english and counter_english[word] > 1:\n",
        "    vocab_english[word] = count\n",
        "    count += 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWlB30c_cjRL",
        "colab_type": "code",
        "outputId": "76cc9373-08b2-4e55-d949-0d729ecaf1fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(vocab_hindi['<sos>'])\n",
        "vocab_english['<sos>']"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSQXAC9woiuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_vocab_hindi = dict((i,word) for word, i in vocab_hindi.items())\n",
        "reverse_vocab_english = dict((i,word) for word, i in vocab_english.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvkoCnN4pWgo",
        "colab_type": "code",
        "outputId": "701e3db3-5cdc-4d2f-86f0-23d6ed99757a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "reverse_vocab_english[1125]"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'independent'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XspKSBYCGK2-",
        "colab_type": "code",
        "outputId": "5a99630d-745b-42a5-838a-cbf6e69875b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(len(vocab_english), len(vocab_hindi))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13445 16917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzLV1lLxi2RZ",
        "colab_type": "code",
        "outputId": "18a61817-f1a8-4b07-f15b-d5050fae14da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "training_data[5:10]"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'src': ['गढ़मुक्तेश्वर', 'हिंदुओं', 'का', 'पावन', 'तीर्थ', 'है'],\n",
              "  'trg': ['garhmukteshwar',\n",
              "   'is',\n",
              "   'a',\n",
              "   'sacred',\n",
              "   'pilgrimage',\n",
              "   'of',\n",
              "   'the',\n",
              "   'hindus']},\n",
              " {'src': ['चलें', 'गढ़', 'मुक्तेश्वर', 'का', 'गंगा', 'मेला'],\n",
              "  'trg': ['let',\n",
              "   'us',\n",
              "   'go',\n",
              "   'to',\n",
              "   'the',\n",
              "   'ganges',\n",
              "   'fair',\n",
              "   'of',\n",
              "   'garh',\n",
              "   'mukteshwar']},\n",
              " {'src': ['गाजियाबाद',\n",
              "   'जिले',\n",
              "   'के',\n",
              "   'गढ़',\n",
              "   'मुक्तेश्वर',\n",
              "   'में',\n",
              "   'पतित',\n",
              "   'पावनी',\n",
              "   'गंगा',\n",
              "   'के',\n",
              "   'तट',\n",
              "   'पर',\n",
              "   'हर',\n",
              "   'साल',\n",
              "   'कार्तिक',\n",
              "   'पूर्णिमा',\n",
              "   'के',\n",
              "   'अवसर',\n",
              "   'पर',\n",
              "   'लगने',\n",
              "   'वाले',\n",
              "   'उत्तर',\n",
              "   'भारत',\n",
              "   'के',\n",
              "   'प्रसिद्ध',\n",
              "   'और',\n",
              "   'प्राचीन',\n",
              "   'धार्मिक',\n",
              "   'मेले',\n",
              "   'का',\n",
              "   'इतिहास',\n",
              "   'लगभग',\n",
              "   'पाँच',\n",
              "   'हजार',\n",
              "   'वर्ष',\n",
              "   'पुराना',\n",
              "   'है'],\n",
              "  'trg': ['the',\n",
              "   'history',\n",
              "   'of',\n",
              "   'north',\n",
              "   'india',\n",
              "   's',\n",
              "   'famous',\n",
              "   'and',\n",
              "   'ancient',\n",
              "   'religious',\n",
              "   'fair',\n",
              "   'held',\n",
              "   'every',\n",
              "   'year',\n",
              "   'on',\n",
              "   'the',\n",
              "   'occasion',\n",
              "   'of',\n",
              "   'kartik',\n",
              "   'poornima',\n",
              "   'on',\n",
              "   'the',\n",
              "   'banks',\n",
              "   'of',\n",
              "   'the',\n",
              "   'fallen',\n",
              "   'purgator',\n",
              "   'ganges',\n",
              "   'in',\n",
              "   'the',\n",
              "   'garh',\n",
              "   'mukteshwar',\n",
              "   'of',\n",
              "   'ghaziabad',\n",
              "   'district']},\n",
              " {'src': ['इस',\n",
              "   'बार',\n",
              "   'भी',\n",
              "   'गढ़',\n",
              "   'मुक्तेश्वर',\n",
              "   'में',\n",
              "   'मेले',\n",
              "   'की',\n",
              "   'भरपूर',\n",
              "   'गहमागहमी',\n",
              "   'है',\n",
              "   'और',\n",
              "   'मुख्य',\n",
              "   'स्नान',\n",
              "   'के',\n",
              "   'लिए',\n",
              "   'श्रद्धालुओं',\n",
              "   'की',\n",
              "   'भारी',\n",
              "   'भीड़',\n",
              "   'जुट',\n",
              "   'रही',\n",
              "   'है'],\n",
              "  'trg': ['there',\n",
              "   'is',\n",
              "   'full',\n",
              "   'fervor',\n",
              "   'of',\n",
              "   'the',\n",
              "   'fair',\n",
              "   'this',\n",
              "   'time',\n",
              "   'also',\n",
              "   'in',\n",
              "   'garh',\n",
              "   'mukteshwar',\n",
              "   'and',\n",
              "   'huge',\n",
              "   'crowd',\n",
              "   'of',\n",
              "   'devotees',\n",
              "   'is',\n",
              "   'gathering',\n",
              "   'for',\n",
              "   'the',\n",
              "   'holy',\n",
              "   'dip']},\n",
              " {'src': ['मुख्य', 'स्नान', 'नवंबर', 'को', 'है'],\n",
              "  'trg': ['the', 'holy', 'dip', 'is', 'on', 'november']}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TK6E-Qm_W96l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorization(data):\n",
        "  for item in data:\n",
        "    wordvec_english = []\n",
        "    wordvec_hindi = []\n",
        "    for word in item['src']:\n",
        "      if word not in vocab_hindi:\n",
        "        word = '<unk>'\n",
        "      wordvec_hindi.append(vocab_hindi[word])\n",
        "    item['src'] = wordvec_hindi[::-1]\n",
        "    \n",
        "    for word in item['trg']:\n",
        "      if word not in vocab_english:\n",
        "        word = '<unk>'\n",
        "      wordvec_english.append(vocab_english[word])\n",
        "    item['trg'] = wordvec_english\n",
        "  return data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbP2IHF1YeSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorized_data = vectorization(training_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq7TVQppd5Tc",
        "colab_type": "code",
        "outputId": "09764e53-0c75-48c8-eba8-4e97f8af6d59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "vectorized_data[:2]"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'src': [11, 10, 9, 8, 7, 6, 5, 4], 'trg': [4, 5, 6, 7, 8, 9, 10, 11, 12]},\n",
              " {'src': [23, 22, 21, 20, 19, 7, 18, 17, 16, 15, 14, 13, 12],\n",
              "  'trg': [13, 14, 15, 16, 17, 18, 19, 10, 20]}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldGolFUrUVlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_vectorized_data = vectorization(valid_data)\n",
        "testing_vectorized_data = vectorization(testing_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4V5DasdUwIo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQX9ROq5kcdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_iterator(data,batch_size):\n",
        "  iterator = []\n",
        "  data.sort(key = lambda x: len(x['src']))\n",
        "  for i in range(0,len(data),batch_size):\n",
        "    iterator.append(data[i:i+batch_size])\n",
        "  return iterator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPqwxzLXwRwD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_iterator = batch_iterator(vectorized_data, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsjygmS3U26m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_iterator = batch_iterator(valid_vectorized_data, batch_size)\n",
        "testing_iterator = batch_iterator(testing_vectorized_data, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnDVL431jWaI",
        "colab_type": "code",
        "outputId": "639a2511-85c9-4597-9ede-8937626b65fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(len(training_iterator[0]), len(valid_iterator), len(testing_iterator))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "64 156 156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2mBe0OyWCQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def padding(batch_data):\n",
        "  max_length = 0\n",
        "  for item in batch_data:\n",
        "    max_length = max(max_length, len(item['src']), len(item['trg']))\n",
        "  \n",
        "  for item in batch_data:\n",
        "    extra_src = max_length - len(item['src'])\n",
        "    extra_trg = max_length - len(item['trg'])\n",
        "    item['src'] = [0] + item['src'] + [3]*extra_src + [1]\n",
        "    item['trg'] = [0] + item['trg'] + [3]*extra_trg + [1]\n",
        "  return batch_data\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7X8GiFdWlKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batched_iterator = []\n",
        "for batch in training_iterator:\n",
        "  batched_iterator.append(padding(batch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id31pJT8WBkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_padded_iterator = []\n",
        "for batch in valid_iterator:\n",
        "  valid_padded_iterator.append(padding(batch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Weeu6HWWRQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testing_padded_iterator = []\n",
        "for batch in testing_iterator:\n",
        "  testing_padded_iterator.append(padding(batch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_5eK7_revce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.hid_dim = hid_dim #dimension of hidden and cell states\n",
        "        self.n_layers = n_layers #layers in the RNN\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim) #nn.Embedding is to convert the one-hot encodings into dense vector\n",
        "        \n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout) #Embeddings of sentence X is passed into RNN with dropout applied to them.\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout) #Dropout to be applied between the layers of a multi-layer RNN, i.e., btw hidden states output\n",
        "        \n",
        "    def forward(self, src):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        \n",
        "        #embedded = [src len, batch size, emb dim]\n",
        "        \n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\n",
        "        \n",
        "        #outputs = [src len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #outputs are always from the top hidden layer\n",
        "        \n",
        "        return hidden, cell"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBij-_HSqdBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.output_dim = output_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, cell):\n",
        "        \n",
        "\n",
        "        #input = [batch size]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #n directions in the decoder will both always be 1, therefore:\n",
        "        #hidden = [n layers, batch size, hid dim]\n",
        "        #context = [n layers, batch size, hid dim]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        #input = [1, batch size]\n",
        "        #print(\"Decoder Input/\",input)\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        \n",
        "        #embedded = [1, batch size, emb dim]\n",
        "                \n",
        "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "        \n",
        "        #output = [seq len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #cell = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #seq len and n directions will always be 1 in the decoder, therefore:\n",
        "        #output = [1, batch size, hid dim]\n",
        "        #hidden = [n layers, batch size, hid dim]\n",
        "        #cell = [n layers, batch size, hid dim]\n",
        "        \n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        \n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden, cell"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Kx0ftvBqisn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
        "             \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        assert encoder.n_layers == decoder.n_layers, \\\n",
        "             \"Encoder and decoder must have equal number of layers!\"\n",
        "        \n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
        "        \n",
        "        batch_size = trg.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        # print(batch_size, trg_len, trg_vocab_size)\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
        "        hidden, cell = self.encoder(src)\n",
        "        \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = trg[0,:]\n",
        "        \n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            #insert input token embedding, previous hidden and previous cell states\n",
        "            #receive output tensor (predictions) and new hidden and cell states\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            \n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input = trg[t] if teacher_force else top1\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ywrv9vSZqngK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(vocab_hindi)\n",
        "OUTPUT_DIM = len(vocab_english)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 128\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWBFhyZOqorX",
        "colab_type": "code",
        "outputId": "72c30350-f04b-4006-c6d4-cbe261911cf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
        "        \n",
        "model.apply(init_weights)\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(16917, 256)\n",
              "    (rnn): LSTM(256, 128, num_layers=2, dropout=0.5)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(13445, 256)\n",
              "    (rnn): LSTM(256, 128, num_layers=2, dropout=0.5)\n",
              "    (fc_out): Linear(in_features=128, out_features=13445, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk9Sy_FEq2Qb",
        "colab_type": "code",
        "outputId": "d542768b-340e-44b2-8621-a8ea431e5995",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 10,166,533 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjxdFNamq5Pn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "learning_rate=0.005\n",
        "optimizer = optim.Adam(model.parameters(), weight_decay=0.01, lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7EXcS0htUAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index = 3).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ-8c6sltgzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        #print(i)\n",
        "        src = torch.t(torch.LongTensor([item['src'] for item in batch])).to(device)\n",
        "        \n",
        "        trg = torch.t(torch.LongTensor([item['trg'] for item in batch])).to(device)\n",
        "        # print(src.shape, trg.shape)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, trg)\n",
        "        \n",
        "        #trg = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].contiguous().view(-1, output_dim)\n",
        "        trg = trg[1:].contiguous().view(-1)\n",
        "        \n",
        "        # trg = [(trg_len - 1) * batch size]\n",
        "        # output = [(trg len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTUKkcKitnBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = torch.LongTensor([item['src'] for item in batch]).to(device)\n",
        "            trg = torch.LongTensor([item['trg'] for item in batch]).to(device)\n",
        "\n",
        "            # src.to(device)\n",
        "            # trg.to(device)\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            #trg = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "            #trg = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator) , output, trg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S4PUXwHttfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEsNaL7atwf3",
        "colab_type": "code",
        "outputId": "074b25bc-c8c0-4d23-c3db-6bb49d4b5d8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        }
      },
      "source": [
        "import time\n",
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, batched_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss, _, _ = evaluate(model, valid_padded_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 52s\n",
            "\tTrain Loss: 6.585 | Train PPL: 724.460\n",
            "\t Val. Loss: 7.143 |  Val. PPL: 1265.037\n",
            "Epoch: 02 | Time: 0m 52s\n",
            "\tTrain Loss: 6.603 | Train PPL: 737.632\n",
            "\t Val. Loss: 7.190 |  Val. PPL: 1325.855\n",
            "Epoch: 03 | Time: 0m 52s\n",
            "\tTrain Loss: 6.608 | Train PPL: 741.163\n",
            "\t Val. Loss: 7.175 |  Val. PPL: 1306.270\n",
            "Epoch: 04 | Time: 0m 52s\n",
            "\tTrain Loss: 6.608 | Train PPL: 741.179\n",
            "\t Val. Loss: 7.149 |  Val. PPL: 1272.649\n",
            "Epoch: 05 | Time: 0m 52s\n",
            "\tTrain Loss: 6.606 | Train PPL: 739.807\n",
            "\t Val. Loss: 7.190 |  Val. PPL: 1326.704\n",
            "Epoch: 06 | Time: 0m 52s\n",
            "\tTrain Loss: 6.611 | Train PPL: 743.588\n",
            "\t Val. Loss: 7.078 |  Val. PPL: 1185.409\n",
            "Epoch: 07 | Time: 0m 52s\n",
            "\tTrain Loss: 6.617 | Train PPL: 747.377\n",
            "\t Val. Loss: 7.095 |  Val. PPL: 1206.319\n",
            "Epoch: 08 | Time: 0m 52s\n",
            "\tTrain Loss: 6.613 | Train PPL: 744.931\n",
            "\t Val. Loss: 7.195 |  Val. PPL: 1333.137\n",
            "Epoch: 09 | Time: 0m 52s\n",
            "\tTrain Loss: 6.609 | Train PPL: 741.945\n",
            "\t Val. Loss: 7.162 |  Val. PPL: 1289.276\n",
            "Epoch: 10 | Time: 0m 52s\n",
            "\tTrain Loss: 6.612 | Train PPL: 743.623\n",
            "\t Val. Loss: 7.094 |  Val. PPL: 1204.413\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_HO88Zqp57h",
        "colab_type": "code",
        "outputId": "66293e08-51e7-4626-f2ea-e6eb5e06b096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "\n",
        "test_loss, output, trg = evaluate(model, batched_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 7.195 | Test PPL: 1332.466 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kg61uVGpULJ2",
        "colab_type": "code",
        "outputId": "58889138-73d3-48e6-88b9-c07c1a94cb54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(testing_padded_iterator[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 572
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1cCjswrUStm",
        "colab_type": "code",
        "outputId": "72180655-6d3e-47dd-bdaf-24342c3ade77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-5.1434, -0.6571, -5.1204,  ..., -3.9024, -4.5438, -2.8950],\n",
              "        [-4.7056, -0.5464, -4.5724,  ..., -3.3813, -4.0453, -2.4985],\n",
              "        [-4.6637, -0.5369, -4.5335,  ..., -3.3454, -4.0013, -2.4879],\n",
              "        ...,\n",
              "        [-6.4607,  0.3734, -6.4324,  ..., -5.1611, -5.7032, -4.3896],\n",
              "        [-6.4597,  0.3733, -6.4311,  ..., -5.1595, -5.7012, -4.3888],\n",
              "        [-6.4865,  0.3765, -6.4671,  ..., -5.2031, -5.7533, -4.4107]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 385
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXKwwEWeUk4j",
        "colab_type": "code",
        "outputId": "6bc02173-b990-4dbd-b342-d216818cab8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trg"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  0, 173,  30,  ...,   3,   3,   1], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 389
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69D7IuY7VEY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate_sentence(sentence, model, device):\n",
        "    \n",
        "    model.eval()\n",
        "    word2vec = [0]    \n",
        "    for word in sentence:\n",
        "      if word not in vocab_hindi:\n",
        "        word = '<unk>'\n",
        "      word2vec.append(vocab_hindi[word])\n",
        "    word2vec.append(1)\n",
        "   \n",
        "    print(word2vec)\n",
        "    src_tensor = torch.LongTensor(word2vec).unsqueeze(1).to(device) \n",
        "    print(src_tensor)  \n",
        "\n",
        "    with torch.no_grad():\n",
        "        hidden, cell = model.encoder(src_tensor) \n",
        "    trg_indexes = [0] \n",
        "    print(\"src_tensor\", src_tensor)\n",
        "    print(\"HIdden\", hidden.shape, cell.shape)\n",
        "    for i in range(50):\n",
        "\n",
        "      trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "      print(trg_tensor)\n",
        "      with torch.no_grad():\n",
        "          output, h, c = model.decoder(trg_tensor, hidden, cell)\n",
        "      print(\"output:\" ,output)\n",
        "\n",
        "      pred_token = output.argmax(1).item()\n",
        "      print(pred_token)\n",
        "\n",
        "      trg_indexes.append(pred_token)\n",
        "      if pred_token == 2:\n",
        "          break\n",
        "   \n",
        "    output = [reverse_vocab_english[i] for i in trg_indexes]\n",
        "    print(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j1qR6rECRDM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4e7e39f4-ae96-4854-af79-aa185cc86347"
      },
      "source": [
        "s = ['छाती', 'में', 'तेज', 'दर्द', 'अथवा', 'सांस','लेने', 'में', 'तकलीफ', 'हो']\n",
        "translate_sentence(s, model, device)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['participants', 'of', '<unk>', 'who', 'Allah', 'breaking', 'Bharatha', 'to', '<unk>', 'of', 'predominant', 'Bhagat']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}