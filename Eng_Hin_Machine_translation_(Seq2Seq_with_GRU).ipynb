{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Eng-Hin Machine-translation (Seq2Seq with GRU).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C98Mokc8K3Uu",
        "colab_type": "code",
        "outputId": "56d6ae9c-7a7f-4625-c9c3-6eae7d1d3248",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "pip install indic-nlp-library"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting indic-nlp-library\n",
            "  Downloading https://files.pythonhosted.org/packages/f0/58/8d1e621f87bbc4217fb8ce6628a2eb08b65a64582c5531becf41da5d721c/indic_nlp_library-0.6-py3-none-any.whl\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from indic-nlp-library) (1.0.3)\n",
            "Collecting morfessor\n",
            "  Downloading https://files.pythonhosted.org/packages/39/e6/7afea30be2ee4d29ce9de0fa53acbb033163615f849515c0b1956ad074ee/Morfessor-2.0.6-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from indic-nlp-library) (1.18.2)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->indic-nlp-library) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->indic-nlp-library) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->indic-nlp-library) (1.12.0)\n",
            "Installing collected packages: morfessor, indic-nlp-library\n",
            "Successfully installed indic-nlp-library-0.6 morfessor-2.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiW631bSNYG-",
        "colab_type": "code",
        "outputId": "4abecba5-ea1a-4a1b-b02e-3a79cc2f4bdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "pip install torchtext==0.5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/ef/54b8da26f37787f5c670ae2199329e7dccf195c060b25628d99e587dac51/torchtext-0.5.0-py3-none-any.whl (73kB)\n",
            "\r\u001b[K     |████▌                           | 10kB 26.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 30kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 51kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 61kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 71kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.5) (1.12.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\r\u001b[K     |▎                               | 10kB 27.4MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 34.1MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 41.4MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 26.0MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 20.6MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 23.2MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 7.6MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 8.3MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 9.1MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102kB 9.6MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112kB 9.6MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 9.6MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 9.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 143kB 9.6MB/s eta 0:00:01\r\u001b[K     |████▊                           | 153kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 194kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 204kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 215kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 225kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 235kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 245kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 256kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 266kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 276kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 286kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 296kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 307kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 317kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 327kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 337kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 348kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 358kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 368kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 378kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 389kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 399kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 409kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 419kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 430kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 440kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 450kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 460kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 471kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 481kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 491kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 501kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 512kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 522kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 532kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 542kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 552kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 563kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 573kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 583kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 593kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 604kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 614kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 624kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 634kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 645kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 655kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 665kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 675kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 686kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 696kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 706kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 716kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 727kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 737kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 747kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 757kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 768kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 778kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 788kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 798kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 808kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 819kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 829kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 839kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 849kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 860kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 870kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 880kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 890kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 901kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 911kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 921kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 931kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 942kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 952kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 962kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 972kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 983kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 993kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0MB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.0MB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 9.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.5) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.5) (1.18.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.5) (1.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.5) (4.38.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.5) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.5) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.5) (3.0.4)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed sentencepiece-0.1.85 torchtext-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KE45-AvK_cL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import codecs\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import math\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQa5YjQwMqnr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 21\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rBXAaNnbpQ8",
        "colab_type": "code",
        "outputId": "66296a8b-a16e-4d85-c67f-557bfa807811",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgDrgOFaLn9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with codecs.open('/content/drive/My Drive/Colab Notebooks/traing_english.txt', encoding='utf-8') as f:\n",
        "  training_english = f.read().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JYBg6MLLxSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with codecs.open('/content/drive/My Drive/Colab Notebooks/traing_hindi.txt', encoding='utf-8') as f:\n",
        "  training_hindi = f.read().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rDGTNsbC_xy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with codecs.open('/content/drive/My Drive/Colab Notebooks/testing_english.txt', encoding='utf-8') as f:\n",
        "  testing_english = f.read().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZeyc5XYDML_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with codecs.open('/content/drive/My Drive/Colab Notebooks/testing_hindi.txt', encoding='utf-8') as f:\n",
        "  testing_hindi = f.read().split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnpCpm93Opmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from indicnlp.tokenize import indic_tokenize  \n",
        "from nltk.tokenize import RegexpTokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ngDYXIU8Pnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenizer(hindi, english, flag):\n",
        "  data = []\n",
        "  corpus_hindi = ['<sos>','<eos>','<unk>','<pad>']\n",
        "  corpus_english = ['<sos>','<eos>','<unk>','<pad>']\n",
        "  tokenizer_english = RegexpTokenizer('\\w+|\\$[\\.]+|\\S+')\n",
        "  for sentence_hindi, sentence_english in zip(hindi, english):\n",
        "    dic = {}\n",
        "    h = indic_tokenize.trivial_tokenize(sentence_hindi)\n",
        "    e = tokenizer_english.tokenize(sentence_english)\n",
        "    if flag:\n",
        "      corpus_hindi += h\n",
        "      corpus_english += e\n",
        "    dic['src'] = e\n",
        "    dic['trg'] = h\n",
        "    data.append(dic)\n",
        "  return data, corpus_hindi, corpus_english"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEW6QHEoPegr",
        "colab_type": "code",
        "outputId": "e499d07e-d4b3-45b3-c830-8d21885c16fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "training_data, corpus_hindi, corpus_english = tokenizer(training_hindi,training_english, True)\n",
        "training_data[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'src': ['dwarka',\n",
              "  'is',\n",
              "  'also',\n",
              "  'a',\n",
              "  'dhaam',\n",
              "  'among',\n",
              "  'the',\n",
              "  'chaar',\n",
              "  'dhaams'],\n",
              " 'trg': ['द्वारका', 'चार', 'धामों', 'में', 'एक', 'धाम', 'भी', 'है']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rgw0ViTL3LrF",
        "colab_type": "code",
        "outputId": "925747a0-2072-4bb9-c32e-2750ae501923",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "type(training_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zez7alYOL8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# testing_data, _, _ = tokenizer(testing_hindi, testing_english, False)\n",
        "# testing_data[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZL1z3mRmkVR",
        "colab_type": "code",
        "outputId": "495c3bbc-f444-48b3-f437-1df853c56bad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "valid_test_data, _, _ = tokenizer(testing_hindi, testing_english, False)\n",
        "valid_test_data[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'src': ['the',\n",
              "  'place',\n",
              "  'baidadih',\n",
              "  'is',\n",
              "  'famous',\n",
              "  'for',\n",
              "  'the',\n",
              "  'big',\n",
              "  'well'],\n",
              " 'trg': ['बैदाडीह', 'स्थान', 'बड़े', 'कुएँ', 'के', 'लिए', 'प्रसिद्ध', 'है']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A5EEmCmotpn",
        "colab_type": "code",
        "outputId": "702bd7ed-31de-4cf0-eb03-1f84f3f96110",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "valid_test_data[15000]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'src': ['only', 'one', 'family', 'stays', 'over', 'here'],\n",
              " 'trg': ['यहाँ', 'अब', 'एक', 'ही', 'परिवार', 'रहता', 'है']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHfI-oJ3mu42",
        "colab_type": "code",
        "outputId": "853b29c6-4279-476d-ace8-b0004be0f751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "valid_data = valid_test_data[:len(valid_test_data)//2]\n",
        "testing_data = valid_test_data[len(valid_test_data)//2:]\n",
        "print(len(valid_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9980\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEI11VRxilHQ",
        "colab_type": "code",
        "outputId": "a051fb3d-a292-4b7a-9e77-7cfb13f21660",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(len(testing_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9981\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp12Xy7ClRcS",
        "colab_type": "code",
        "outputId": "a89a19e1-130a-4484-ad2d-b620b87151d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "testing_data[5219] #Test example"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'src': ['first',\n",
              "  'of',\n",
              "  'all',\n",
              "  'asia',\n",
              "  'is',\n",
              "  'divided',\n",
              "  'into',\n",
              "  'sea',\n",
              "  'and',\n",
              "  'rivers'],\n",
              " 'trg': ['सर्वप्रथम',\n",
              "  'एशिया',\n",
              "  'समुद्रों',\n",
              "  'और',\n",
              "  'नदियों',\n",
              "  'में',\n",
              "  'बँटा',\n",
              "  'हुआ',\n",
              "  'है']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1qHl3AilR67",
        "colab_type": "code",
        "outputId": "24ecb34a-5ac7-449d-f9aa-854644b6e497",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(testing_english[15000]) #Test example\n",
        "print(testing_hindi[15000])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "only one family stays over here\n",
            "यहाँ अब एक ही परिवार रहता है\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3azoNg3vPMSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "counter_english = Counter(corpus_english)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwXx32biUqrb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_hindi = {}\n",
        "count = 0\n",
        "for i,word in enumerate(corpus_hindi):\n",
        "  if word not in vocab_hindi:\n",
        "    vocab_hindi[word] = count\n",
        "    count += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYzQ2jAR3WrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#vocab_hindi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0YrYBI0VF0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_english = {'<sos>': 0,'<eos>': 1,'<unk>': 2,'<pad>':3}\n",
        "count = 4\n",
        "for i,word in enumerate(corpus_english):\n",
        "  if word not in vocab_english and counter_english[word] > 1:\n",
        "    vocab_english[word] = count\n",
        "    count += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3es1PtMys-_y",
        "colab_type": "code",
        "outputId": "29d2b8ff-40f8-40fc-8277-09a5d31a79e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vocab_english[\"only\"]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "221"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpdgUOkridC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in vocab_hindi:\n",
        "#   print(vocab_hindi[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XspKSBYCGK2-",
        "colab_type": "code",
        "outputId": "4fdb6154-62dd-4e98-d531-324d7a4c01f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(len(vocab_english), len(vocab_hindi))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13445 25598\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzLV1lLxi2RZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training_data[:2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TK6E-Qm_W96l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorization(data):\n",
        "  for item in data:\n",
        "    wordvec_english = []\n",
        "    wordvec_hindi = []\n",
        "    for word in item['src']:\n",
        "      if word not in vocab_english:\n",
        "        word = '<unk>'\n",
        "      wordvec_english.append(vocab_english[word])\n",
        "    item['src'] = wordvec_english[::-1]\n",
        "    \n",
        "    for word in item['trg']:\n",
        "      if word not in vocab_hindi:\n",
        "        word = '<unk>'\n",
        "      wordvec_hindi.append(vocab_hindi[word])\n",
        "    item['trg'] = wordvec_hindi\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbP2IHF1YeSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorized_data = vectorization(training_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TILL-mIn3g-u",
        "colab_type": "code",
        "outputId": "b9d09886-dbd5-4d5a-93ab-78b5e0e0b2fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "type(vectorized_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq7TVQppd5Tc",
        "colab_type": "code",
        "outputId": "316d63cf-aba3-478a-e947-416e00628811",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "vectorized_data[:2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'src': [12, 11, 10, 9, 8, 7, 6, 5, 4], 'trg': [4, 5, 6, 7, 8, 9, 10, 11]},\n",
              " {'src': [20, 10, 19, 18, 17, 16, 15, 14, 13],\n",
              "  'trg': [12, 13, 14, 15, 16, 17, 18, 7, 19, 20, 21, 22, 23]}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukBDkGI5m52T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_vectorized_data = vectorization(valid_data)\n",
        "testing_vectorized_data = vectorization(testing_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4V5DasdUwIo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQX9ROq5kcdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_iterator(data,batch_size):\n",
        "  iterator = []\n",
        "  data.sort(key = lambda x: len(x['src']))\n",
        "  for i in range(0,len(data),batch_size):\n",
        "    iterator.append(data[i:i+batch_size])\n",
        "  return iterator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPqwxzLXwRwD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_iterator = batch_iterator(vectorized_data, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhNxiX2znFYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_iterator = batch_iterator(valid_vectorized_data, batch_size)\n",
        "testing_iterator = batch_iterator(testing_vectorized_data, batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dZvUaoU3wRv",
        "colab_type": "code",
        "outputId": "82f5867a-82b8-43f4-e573-530824731e10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(training_iterator[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnDVL431jWaI",
        "colab_type": "code",
        "outputId": "f4452c92-1fa6-472e-96e0-63be741d8e7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "type(training_iterator[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2mBe0OyWCQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def padding(batch_data):\n",
        "  max_lenght = 0\n",
        "  for item in batch_data:\n",
        "    max_lenght = max(max_lenght, len(item['src']), len(item['trg']))\n",
        "  \n",
        "  for item in batch_data:\n",
        "    extra_src = max_lenght - len(item['src'])\n",
        "    extra_trg = max_lenght - len(item['trg'])\n",
        "    item['src'] = [0] + item['src'] + [3]*extra_src + [1]\n",
        "    item['trg'] = [0] + item['trg'] + [3]*extra_trg + [1]\n",
        "  return batch_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7X8GiFdWlKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batched_iterator = []\n",
        "for batch in training_iterator:\n",
        "  batched_iterator.append(padding(batch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odLP0IeInKDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_padded_iterator = []\n",
        "for batch in valid_iterator:\n",
        "  valid_padded_iterator.append(padding(batch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Iskq7sCnKns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testing_padded_iterator = []\n",
        "for batch in testing_iterator:\n",
        "  testing_padded_iterator.append(padding(batch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tvISwIrShq8",
        "colab_type": "code",
        "outputId": "5620912e-16aa-42cc-c1a3-373d23a838d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZSCVKZglP-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hid_dim = hid_dim\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim) #no dropout as only one layer!\n",
        "        \n",
        "        self.rnn = nn.GRU(emb_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        \n",
        "        #embedded = [src len, batch size, emb dim]\n",
        "        \n",
        "        outputs, hidden = self.rnn(embedded) #no cell state!\n",
        "        \n",
        "        #outputs = [src len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #outputs are always from the top hidden layer\n",
        "        \n",
        "        return hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJn16Ze6lXn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hid_dim = hid_dim\n",
        "        self.output_dim = output_dim\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.GRU(emb_dim + hid_dim, hid_dim)\n",
        "        \n",
        "        self.fc_out = nn.Linear(emb_dim + hid_dim * 2, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, context):\n",
        "        \n",
        "        #input = [batch size]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        #context = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #n layers and n directions in the decoder will both always be 1, therefore:\n",
        "        #hidden = [1, batch size, hid dim]\n",
        "        #context = [1, batch size, hid dim]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        #input = [1, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        \n",
        "        #embedded = [1, batch size, emb dim]\n",
        "                \n",
        "        emb_con = torch.cat((embedded, context), dim = 2)\n",
        "            \n",
        "        #emb_con = [1, batch size, emb dim + hid dim]\n",
        "            \n",
        "        output, hidden = self.rnn(emb_con, hidden)\n",
        "        \n",
        "        #output = [seq len, batch size, hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, hid dim]\n",
        "        \n",
        "        #seq len, n layers and n directions will always be 1 in the decoder, therefore:\n",
        "        #output = [1, batch size, hid dim]\n",
        "        #hidden = [1, batch size, hid dim]\n",
        "        \n",
        "        output = torch.cat((embedded.squeeze(0), hidden.squeeze(0), context.squeeze(0)), \n",
        "                           dim = 1)\n",
        "        \n",
        "        #output = [batch size, emb dim + hid dim * 2]\n",
        "        \n",
        "        prediction = self.fc_out(output)\n",
        "        \n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJiKNZr7mLWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
        "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        \n",
        "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
        "        \n",
        "        batch_size = trg.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #last hidden state of the encoder is the context\n",
        "        context = self.encoder(src)\n",
        "        \n",
        "        #context also used as the initial hidden state of the decoder\n",
        "        hidden = context\n",
        "        \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = trg[0,:]\n",
        "        \n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            #insert input token embedding, previous hidden state and the context state\n",
        "            #receive output tensor (predictions) and new hidden state\n",
        "            output, hidden = self.decoder(input, hidden, context)\n",
        "            \n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            \n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input = trg[t] if teacher_force else top1\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ywrv9vSZqngK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(vocab_english)\n",
        "OUTPUT_DIM = len(vocab_hindi)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, DEC_DROPOUT)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHz4AS_dmqJR",
        "colab_type": "code",
        "outputId": "22b533e3-4198-4408-8e93-206c45619a70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        \n",
        "model.apply(init_weights)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(13445, 256)\n",
              "    (rnn): GRU(256, 512)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(25598, 256)\n",
              "    (rnn): GRU(768, 512)\n",
              "    (fc_out): Linear(in_features=1280, out_features=25598, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk9Sy_FEq2Qb",
        "colab_type": "code",
        "outputId": "37bbdd1a-878f-4c95-b775-299e7e31e4b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 45,937,918 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjxdFNamq5Pn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7EXcS0htUAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index = 3).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5o5Alrc5PeS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i, batch in enumerate(batched_iterator):\n",
        "#   if i==0:\n",
        "#     #print([item['src'] for item in batch])\n",
        "#     src = torch.LongTensor([item['src'] for item in batch])\n",
        "#     #print(\"src:\",src)\n",
        "#     print(src.shape)\n",
        "#     trg = torch.LongTensor([item['trg'] for item in batch])\n",
        "#     #print(\"trg:\",trg)\n",
        "#     print(trg.shape)\n",
        "#     #print([item['trg'] for item in batch])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJm4TPE5BE-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i, batch in enumerate(batched_iterator):\n",
        "#   if i==0:\n",
        "#     #print([item['src'] for item in batch])\n",
        "#     #src = torch.LongTensor([item['src'] for item in batch])\n",
        "\n",
        "#     print([item['src'] for item in batch])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ-8c6sltgzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = torch.t(torch.LongTensor([item['src'] for item in batch])).to(device)\n",
        "        trg = torch.t(torch.LongTensor([item['trg'] for item in batch])).to(device)\n",
        "        \n",
        "        #print([item['src'] for item in batch])\n",
        "        #src = torch.LongTensor([item['src'] for item in batch])\n",
        "        #print((src))\n",
        "        #trg = torch.LongTensor([item['trg'] for item in batch])\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, trg)\n",
        "        \n",
        "        #trg = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        #output = output[1:].view(-1, output_dim)\n",
        "        output = output[1:].contiguous().view(-1, output_dim)\n",
        "        trg = trg[1:].contiguous().view(-1)\n",
        "        \n",
        "        #trg = [(trg len - 1) * batch size]\n",
        "        #output = [(trg len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTUKkcKitnBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = torch.t(torch.LongTensor([item['src'] for item in batch])).to(device)\n",
        "            trg = torch.t(torch.LongTensor([item['trg'] for item in batch])).to(device)\n",
        "\n",
        "            #src = torch.LongTensor([item['src'] for item in batch])\n",
        "            #trg = torch.LongTensor([item['trg'] for item in batch])\n",
        "\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            #trg = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].contiguous().view(-1, output_dim)\n",
        "            trg = trg[1:].contiguous().view(-1)\n",
        "\n",
        "            #trg = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S4PUXwHttfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEsNaL7atwf3",
        "colab_type": "code",
        "outputId": "b69c3c01-6403-46a0-9b7e-7ad6007a12f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        }
      },
      "source": [
        "import time\n",
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, batched_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_padded_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    #print(train_loss)\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 2m 4s\n",
            "\tTrain Loss: 6.790 | Train PPL: 888.580\n",
            "\t Val. Loss: 8.153 |  Val. PPL: 3475.271\n",
            "Epoch: 02 | Time: 2m 3s\n",
            "\tTrain Loss: 5.873 | Train PPL: 355.379\n",
            "\t Val. Loss: 7.820 |  Val. PPL: 2489.176\n",
            "Epoch: 03 | Time: 2m 3s\n",
            "\tTrain Loss: 5.340 | Train PPL: 208.441\n",
            "\t Val. Loss: 7.953 |  Val. PPL: 2844.537\n",
            "Epoch: 04 | Time: 2m 3s\n",
            "\tTrain Loss: 4.783 | Train PPL: 119.453\n",
            "\t Val. Loss: 7.952 |  Val. PPL: 2842.422\n",
            "Epoch: 05 | Time: 2m 3s\n",
            "\tTrain Loss: 4.226 | Train PPL:  68.474\n",
            "\t Val. Loss: 8.145 |  Val. PPL: 3444.877\n",
            "Epoch: 06 | Time: 2m 3s\n",
            "\tTrain Loss: 3.765 | Train PPL:  43.180\n",
            "\t Val. Loss: 8.120 |  Val. PPL: 3359.649\n",
            "Epoch: 07 | Time: 2m 3s\n",
            "\tTrain Loss: 3.390 | Train PPL:  29.661\n",
            "\t Val. Loss: 8.265 |  Val. PPL: 3883.621\n",
            "Epoch: 08 | Time: 2m 3s\n",
            "\tTrain Loss: 3.096 | Train PPL:  22.102\n",
            "\t Val. Loss: 8.535 |  Val. PPL: 5091.567\n",
            "Epoch: 09 | Time: 2m 3s\n",
            "\tTrain Loss: 2.876 | Train PPL:  17.748\n",
            "\t Val. Loss: 8.628 |  Val. PPL: 5586.818\n",
            "Epoch: 10 | Time: 2m 3s\n",
            "\tTrain Loss: 2.672 | Train PPL:  14.470\n",
            "\t Val. Loss: 8.669 |  Val. PPL: 5821.398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93Ro4tK3MFwD",
        "colab_type": "code",
        "outputId": "f00934e9-0c72-4b32-f4b3-72d2ab4ce67e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.load_state_dict(torch.load('tut2-model.pt'))\n",
        "\n",
        "test_loss = evaluate(model, testing_padded_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 7.762 | Test PPL: 2350.606 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UedRbzz3WF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reverse_vocab_hindi = dict((i,word) for word, i in vocab_hindi.items())\n",
        "reverse_vocab_english = dict((i,word) for word, i in vocab_english.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDbHF17q20Hj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate_sentence(sentence, model, device, max_len = 50):\n",
        "    \n",
        "    # model.eval()\n",
        "    # word2vec = [0]    \n",
        "    # for word in sentence:\n",
        "    #   if word not in vocab_english:\n",
        "    #     word = '<unk>'\n",
        "    #   word2vec.append(vocab_english[word])\n",
        "    # word2vec.append(1)\n",
        "\n",
        "    model.eval()\n",
        "    word2vec = [1]    \n",
        "    for word in sentence:\n",
        "      if word not in vocab_english:\n",
        "        word = '<unk>'\n",
        "      word2vec.append(vocab_english[word])\n",
        "    word2vec.append(0)\n",
        "    word2vec = word2vec[::-1]\n",
        "\n",
        "    # word2vec = []\n",
        "    # for word in sentence:\n",
        "    #   if word not in vocab_english:\n",
        "    #     word = '<unk>'\n",
        "    #   word2vec.append(vocab_english[word])\n",
        "    # word2vec=word2vec[::-1]\n",
        "    # word2vec=[0]+word2vec+[1]\n",
        "\n",
        "    src_tensor = torch.LongTensor(word2vec).unsqueeze(0).to(device)   \n",
        "    with torch.no_grad():\n",
        "        hidden, cell = model.encoder(src_tensor)\n",
        "        #print(hidden, cell)    \n",
        "    print(src_tensor[0])\n",
        "    with torch.no_grad():\n",
        "        prediction, h, c = model.decoder(src_tensor[0],hidden, cell)\n",
        "    \n",
        "    #print(\"prediction\",prediction, prediction.shape)\n",
        "\n",
        "    translation_tensor = torch.argmax(prediction.squeeze(1), 1)\n",
        "    #print(translation_tensor)\n",
        "    pred_indexes=translation_tensor.data.tolist()\n",
        "    output = [reverse_vocab_hindi[i] for i in pred_indexes]\n",
        "    print(\" \".join(output))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osJloHre3rWc",
        "colab_type": "code",
        "outputId": "c39100a0-4d9c-4dfc-cbc8-e9e6e4cf67de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "source = ['dwarka','is','also','a','dhaam','among','the','chaar','dhaams']\n",
        "translate_sentence(source,model,device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ही रंग तो है में एक में लायक बार में झील\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcOwJbRi54PR",
        "colab_type": "code",
        "outputId": "500e190d-75e7-430e-b778-f0398bba7da7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "source = [\"how\", \"to\", \"reach\", \"jammu\"]\n",
        "translate_sentence(source,model,device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ही के में रूप सकेगा झील\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZL0ZbFP6rIm",
        "colab_type": "code",
        "outputId": "873865bc-c32f-46c5-c7d1-4674eb3df19b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "source=[\"it\", \"is\", \"really\", \"adventurous\"]\n",
        "translate_sentence(source,model,device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ही के एक बार सकती झील\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3dvzRTv7f-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence=[\"it\", \"is\", \"really\", \"adventurous\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Spq8M33j7byF",
        "colab_type": "code",
        "outputId": "6a438612-42cc-473d-dad0-ef772733a640",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "word2vec = [1]    \n",
        "for word in sentence:\n",
        "  if word not in vocab_english:\n",
        "    word = '<unk>'\n",
        "  word2vec.append(vocab_english[word])\n",
        "word2vec.append(0)\n",
        "word2vec = word2vec[::-1]\n",
        "\n",
        "# word2vec = []\n",
        "# for word in sentence:\n",
        "#   if word not in vocab_english:\n",
        "#     word = '<unk>'\n",
        "#   word2vec.append(vocab_english[word])\n",
        "# word2vec=word2vec[::-1]\n",
        "# word2vec=[0]+word2vec+[1]\n",
        "\n",
        "src_tensor = torch.LongTensor(word2vec).unsqueeze(0).to(device)   \n",
        "print(src_tensor)\n",
        "with torch.no_grad():\n",
        "    hidden, cell = model.encoder(src_tensor)\n",
        "    #print(hidden, cell)    \n",
        "print(src_tensor[0])\n",
        "\n",
        "with torch.no_grad():\n",
        "    prediction, h, c = model.decoder(src_tensor[0],hidden, cell)\n",
        "\n",
        "#print(\"prediction\",prediction, prediction.shape)\n",
        "\n",
        "translation_tensor = torch.argmax(prediction.squeeze(1), 1)\n",
        "print(translation_tensor)\n",
        "pred_indexes=translation_tensor.data.tolist()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[   0,  979, 3664,    5,   88,    1]], device='cuda:0')\n",
            "tensor([   0,  979, 3664,    5,   88,    1], device='cuda:0')\n",
            "tensor([ 162,   17,    8,   86, 2375, 2398], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}